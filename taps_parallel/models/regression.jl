module Regression

export regression
using LBFGSB
using LinearAlgebra
using ForwardDiff

Database = include("./database.jl")
# include("./models.jl")
using ..Models

nax = [CartesianIndex()]

function regression!(model::Model, MPI, comm)
    # comm = MPI.COMM_WORLD
    nprc = MPI.Comm_size(comm)
    rank = MPI.Comm_rank(comm)
    root = 0

    data = Database.read_data(model.imgdata_filename, model.data_ids)
    攝､, 攝ｦ, 攝 = model.kernel, model.mean, model.descriptor
    # 攝::Array{Float64, 3};   3xAxM -> A x 3(A-1) x M
    # 攝::Array{Float64, 2};   A x M
    # 攝, 攝 = Models.data2攝歴攝(data)
    攝, 攝 = 攝.data2攝歴攝(data)

    A, M = size(攝)
    D = 3 * A
    N = M

    # Parallel read data_ids
    remainder = A % nprc
    quant = zeros(Int64, nprc)
    partn = zeros(Int64, nprc)
    temp = 0
    for i=1:nprc
        quant[i] = A ﾃｷ nprc
        if remainder > 0
            quant[i] += 1
            remainder -= 1 # scope of variable
        end
        partn[i] = temp
        temp += quant[i]
    end

    攝､.hyperparameters = 攝.kernel_hyperparameters(model.kernel_hyperparameters)
    攝ｦ.hyperparameters = 攝.mean_hyperparameters(model.mean_hyperparameters)
    攝､.data, 攝ｦ.data  = 攝, 攝

    nprtn = zeros(Int64, nprc + 1)
    nprtn[2:end] = partn[:]

    sendbuf = []

    optimizer = L_BFGS_B(1024, 17)

    bounds = 攝.kernel_bounds(model.kernel_bounds)

    function likelihood2(hyperparameters, Xmn, Y竢ｦm)
        ﾎ｣竅ｻﾂｹ = zeros(eltype(hyperparameters), 3(A-1), 3(A-1))
        for i in 1:A-1
            ﾎ｣竅ｻﾂｹ[3i-2, 3i-2] = 1 / hyperparameters[i]
            ﾎ｣竅ｻﾂｹ[3i-1, 3i-1] = 1 / hyperparameters[i]
            ﾎ｣竅ｻﾂｹ[3i, 3i] = 1 / hyperparameters[i]
        end
        ﾏダf = hyperparameters[end-1]
        ﾏダn = hyperparameters[end]

        dists = zeros(eltype(hyperparameters), M, N)
        for m in 1:M for n in 1:N
            dists[m, n] = Xmn[:, m, n]' * ﾎ｣竅ｻﾂｹ * Xmn[:, m, n]
        end end

        K = ﾏダf .* exp.(-0.5 * dists)                      # M x N
        if isposdef(K)
            detK = reduce(*, diag(cholesky(K).L))
        else
            detK = max(det(K), 1)
        end
        return log(detK) + 0.5 * Y竢ｦm' * inv(K + ﾏダn * I(M)) * Y竢ｦm
    end

    function likelihood(hyperparameters, Xmn, Y竢ｦm)
        return likelihood2(hyperparameters, Xmn, Y竢ｦm),
               ForwardDiff.gradient(x -> likelihood2(x, Xmn, Y竢ｦm), hyperparameters)
    end

    # for i = nprtn[rank+1]:nprtn[rank+2]-1
    for i = 1:A
        攝､.idx, 攝ｦ.idx = i, i
        Xm = 攝夕i, :, :]                         # 3(A-1) x M
        Y竢ｦm = 攝麓i, :] .- 攝ｦ(Xm)                 # M
        Xmn = (Xm[:, :, nax] .- Xm[:, nax, :])  # 3(A-1) x M x N

        x0 = zeros(Float64, A+1)
        x0[end] = 攝､.hyperparameters[i, end]
        x0[end-1] = 攝､.hyperparameters[i, end-1]
        for j = 1:A-1
            x0[j] = 攝､.hyperparameters[i, 3j]
        end
        # x0 = 攝.regression_fold(xout)
        fout, xout = optimizer(x -> likelihood(x, Xmn, Y竢ｦm), x0, bounds[i, :, :],
                               m=10, factr=1e7, pgtol=1e-5,
                               iprint=-1, maxfun=15000, maxiter=15000)

        攝､.hyperparameters[i, end] = xout[end]
        攝､.hyperparameters[i, end-1] = xout[end-1]
        for j = 1:A-1
            攝､.hyperparameters[i, 3(j-1)+1:3j] .= xout[j]
        end
        # 攝､.hyperparameters[i, :] = 攝.hyperparameters_expand(xout)
        # append(sendbuf, hyperparameters)
    end

    # MPI.ScatterV(sakdfh)

    numbers = model.kernel_hyperparameters["numbers"]
    model.kernel_hyperparameters = 攝.kernel_hyperparameters(攝､.hyperparameters, numbers)
    model.optimized = false
end

function regression!(model::GaussianLite, MPI, comm)
    # comm = MPI.COMM_WORLD
    nprc = MPI.Comm_size(comm)
    rank = MPI.Comm_rank(comm)
    root = 0

    data = Database.read_data(model.imgdata_filename, model.data_ids)
    攝､, 攝ｦ, 攝 = model.kernel, model.mean, model.descriptor
    # 攝::Array{Float64, 3};   3xAxM -> A x 3(A-1) x M
    # 攝::Array{Float64, 2};   A x M
    # 攝, 攝 = Models.data2攝歴攝(data)
    攝, 攝 = 攝.data2攝歴攝(data)
    攝､.data, 攝ｦ.data  = 攝, 攝

    M = size(攝)[end]
    #D = 3 * A
    #N = M
#
    ## Parallel read data_ids
    #remainder = A % nprc
    #quant = zeros(Int64, nprc)
    #partn = zeros(Int64, nprc)
    #temp = 0
    #for i=1:nprc
    #    quant[i] = A ﾃｷ nprc
    #    if remainder > 0
    #        quant[i] += 1
    #        remainder -= 1 # scope of variable
    #    end
    #    partn[i] = temp
    #    temp += quant[i]
    #end
#
#
    #nprtn = zeros(Int64, nprc + 1)
    #nprtn[2:end] = partn[:]
#
    #sendbuf = []

    optimizer = L_BFGS_B(1024, 17)

    bounds = 攝.model2reg_bounds(model.kernel_bounds)

    """
    hyperparameters : DD + 2 shape 1D array
    """
    function likelihood2(ﾎｸ, Xmn, Y竢ｦm)
        撥 = 攝.reg2ker_hyper(ﾎｸ)
        ll = 撥閏1:end-2]       # D
        ﾏダf = 撥閏end-1]
        ﾏダn = 撥閏end]

        dists = dropdims(sum((Xmn ./ ll).^2, dims=1), dims=1)      # MxN
        K = ﾏダf .* exp.(-0.5 * dists)                            # M x N
        if isposdef(K)
            detK = reduce(*, diag(cholesky(K).L))
        else
            detK = max(det(K), 1)
        end
        return log(detK) + 0.5 * Y竢ｦm' * inv(K + ﾏダn * I(M)) * Y竢ｦm
    end

    function likelihood(ﾎｸ, Xmn, Y竢ｦm)
        return likelihood2(ﾎｸ, Xmn, Y竢ｦm),
               ForwardDiff.gradient(x -> likelihood2(x, Xmn, Y竢ｦm), ﾎｸ)
    end

    Y竢ｦm = 攝 .- 攝ｦ(攝)                      # M
    Xmn = (攝夕:, :, nax] .- 攝夕:, nax, :])  # 3A x M x N

    ﾎｸ0 = 攝.model2reg_hyper(model.kernel_hyperparameters)
    fout, ﾎｸout = optimizer(ﾎｸ -> likelihood(ﾎｸ, Xmn, Y竢ｦm), ﾎｸ0, bounds,
                           m=10, factr=1e7, pgtol=1e-5,
                           iprint=-1, maxfun=15000, maxiter=15000)

    # MPI.ScatterV(sakdfh)
    攝､.hyperparameters = 攝.reg2ker_hyper(ﾎｸout)
    model.kernel_hyperparameters = 攝.reg2model_hyper(ﾎｸout)
    model.optimized = false
end

function regression!(model::GaussianLite2, MPI, comm)
    # comm = MPI.COMM_WORLD
    nprc = MPI.Comm_size(comm)
    rank = MPI.Comm_rank(comm)
    root = 0

    data = Database.read_data(model.imgdata_filename, model.data_ids)
    攝､, 攝ｦ, 攝 = model.kernel, model.mean, model.descriptor
    # 攝::Array{Float64, 3};   3xAxM -> A x 3(A-1) x M
    # 攝::Array{Float64, 2};   A x M
    # 攝, 攝 = Models.data2攝歴攝(data)
    攝, 攝 = 攝.data2攝歴攝(data)
    攝､.data, 攝ｦ.data  = 攝, 攝

    M = size(攝)[end]
    #D = 3 * A
    #N = M
#
    ## Parallel read data_ids
    #remainder = A % nprc
    #quant = zeros(Int64, nprc)
    #partn = zeros(Int64, nprc)
    #temp = 0
    #for i=1:nprc
    #    quant[i] = A ﾃｷ nprc
    #    if remainder > 0
    #        quant[i] += 1
    #        remainder -= 1 # scope of variable
    #    end
    #    partn[i] = temp
    #    temp += quant[i]
    #end
#
#
    #nprtn = zeros(Int64, nprc + 1)
    #nprtn[2:end] = partn[:]
#
    #sendbuf = []

    optimizer = L_BFGS_B(1024, 17)

    bounds = 攝.model2reg_bounds(model.kernel_bounds)

    """
    hyperparameters : DD + 2 shape 1D array
    """
    function likelihood2(ﾎｸ, Xmn, Y竢ｦm)
        撥 = 攝.reg2ker_hyper(ﾎｸ)
        ll = 撥閏1:end-2]       # D
        ﾏダf = 撥閏end-2]
        ﾏダne = 撥閏end-1]
        ﾏダnf = 撥閏end]

        dists = dropdims(sum((Xmn ./ ll).^2, dims=1), dims=1)      # MxN
        K = ﾏダf .* exp.(-0.5 * dists)                            # M x N
        M窶ｲ = M < 10 ? M : 10
        fidx = (1:M |> collect)[end-M窶ｲ+1:end]
        Xm窶ｲn = Xmn[:, fidx, :]
        K窶ｲ = K[fidx, :]

        # Derivative coefficient D x M` x N
        dc_gd = -Xm窶ｲn ./ ll
        # DxM窶ｲxN x 1xM窶ｲxN -> DxM窶ｲxN -> DM窶ｲxN
        K窶ｲgd = reshape(dc_gd .* K窶ｲ[nax, :, :], D*M窶ｲ, N)
        # if gradients || hessian
        # DxMxN * 1xMxN -> MxDN
        # Derivative coefficient D x M x N
        dc_gd = -Xmn ./ ll
        Kdg = -dc_gd .* K[nax, :, :]
        # DxMxN -> MxDxN
        Kdg = reshape(permutedims(Kdg, [2, 1, 3]), M, D*N)
        # DxMx1xN  * 1xMxDxN  -> D x M x D x N
        Xnm窶ｲ = permutedims(Xm窶ｲn, [2, 1, 3])
        # DxM窶ｲx1xN  * 1xM窶ｲxDxN  -> D x M窶ｲ x D x N
        dc_dd_glob = -Xm窶ｲn[:, :, nax, :] .* Xnm窶ｲ[nax, :, :, :]
        # # 竏_mn exp(Xn - Xm)^2
        dc_dd_diag = I(D)[:, nax, :, nax] ./ ll
        # DxMxDxN - DxMxDxN
        K窶ｲdd = @. (dc_dd_glob + dc_dd_diag) * K窶ｲ[nax, :, nax, :]
        # DM窶ｲ x DN
        # Kdd = reshape(permutedims(Kdd, [2, 1, 4, 3]), D * M, D * N)
        K窶ｲdd = reshape(K窶ｲdd, D * M窶ｲ, D * N)
        Kext = [K K窶ｲdg;
                K窶ｲgd K窶ｲdd]

        if isposdef(Kext)
            detK = reduce(*, diag(cholesky(Kext).L))
        else
            detK = max(det(Kext), 1)
        end
        KK = [K+ﾏダne*I(M) K窶ｲdg; K窶ｲgd K窶ｲdd+ﾏダnf*I(D*M窶ｲ)]
        return log(detK) + 0.5 * Y竢ｦm' * inv(KK) * Y竢ｦm
    end

    function likelihood(ﾎｸ, Xmn, Y竢ｦm)
        return likelihood2(ﾎｸ, Xmn, Y竢ｦm),
               ForwardDiff.gradient(x -> likelihood2(x, Xmn, Y竢ｦm), ﾎｸ)
    end

    Y竢ｦm = 攝 .- 攝ｦ(攝)                      # M
    Xmn = (攝夕:, :, nax] .- 攝夕:, nax, :])  # 3A x M x N

    ﾎｸ0 = 攝.model2reg_hyper(model.kernel_hyperparameters)
    fout, ﾎｸout = optimizer(ﾎｸ -> likelihood(ﾎｸ, Xmn, Y竢ｦm), ﾎｸ0, bounds,
                           m=10, factr=1e7, pgtol=1e-5,
                           iprint=-1, maxfun=15000, maxiter=15000)

    # MPI.ScatterV(sakdfh)
    攝､.hyperparameters = 攝.reg2ker_hyper(ﾎｸout)
    model.kernel_hyperparameters = 攝.reg2model_hyper(ﾎｸout)
    model.optimized = false
end

function regression!(model::DescriptorGaussian, MPI, comm)
    # comm = MPI.COMM_WORLD
    nprc = MPI.Comm_size(comm)
    rank = MPI.Comm_rank(comm)
    root = 0

    data = Database.read_data(model.imgdata_filename, model.data_ids)
    攝､, 攝ｦ, 攝 = model.kernel, model.mean, model.descriptor
    # 攝::Array{Float64, 3};   3xAxM -> A x 3(A-1) x M
    # 攝::Array{Float64, 2};   A x M
    # 攝, 攝 = Models.data2攝歴攝(data)
    攝, 攝 = 攝.data2攝歴攝(data)

    A, M = size(攝)
    D = 3 * A
    hyperD = 攝.hyperD
    N = M

    # Parallel read data_ids
    remainder = A % nprc
    quant = zeros(Int64, nprc)
    partn = zeros(Int64, nprc)
    temp = 0
    for i=1:nprc
        quant[i] = A ﾃｷ nprc
        if remainder > 0
            quant[i] += 1
            remainder -= 1 # scope of variable
        end
        partn[i] = temp
        temp += quant[i]
    end

    攝､.hyperparameters = 攝.kernel_hyperparameters(model.kernel_hyperparameters)
    攝ｦ.hyperparameters = 攝.mean_hyperparameters(model.mean_hyperparameters)
    攝､.data, 攝ｦ.data  = 攝, 攝

    nprtn = zeros(Int64, nprc + 1)
    nprtn[2:end] = partn[:]

    sendbuf = []

    optimizer = L_BFGS_B(1024, 17)

    bounds = 攝.kernel_bounds(model.kernel_bounds)

    """
    hyperparameters : DD + 2 shape 1D array
    """
    function likelihood2(hyperparameters, Xmn, Y竢ｦm)
        ﾎ｣竅ｻﾂｹ = zeros(eltype(hyperparameters), hyperD, hyperD)
        for i in 1:hyperD
            ﾎ｣竅ｻﾂｹ[i, i] = 1. / hyperparameters[i]
        end
        ﾏダf = hyperparameters[end-1]
        ﾏダn = hyperparameters[end]

        dists = zeros(eltype(hyperparameters), M, N)
        for m in 1:M for n in 1:N
            # dists[m, n] = Xmn[:, m, n]' * ﾎ｣竅ｻﾂｹ * Xmn[:, m, n]
            dists[m, n] = Xmn[:, m, n]' * Xmn[:, m, n] / 0.0001
        end end

        K = ﾏダf .* exp.(-0.5 * dists)                      # M x N
        if isposdef(K)
            detK = reduce(*, diag(cholesky(K).L))
        else
            detK = max(det(K), 1)
        end
        return log(detK) + 0.5 * Y竢ｦm' * inv(K + ﾏダn * I(M)) * Y竢ｦm
    end

    function likelihood(hyperparameters, Xmn, Y竢ｦm)
        return likelihood2(hyperparameters, Xmn, Y竢ｦm),
               ForwardDiff.gradient(x -> likelihood2(x, Xmn, Y竢ｦm), hyperparameters)
    end

    # for i = nprtn[rank+1]:nprtn[rank+2]-1
    for a = 1:A
        攝､.idx, 攝ｦ.idx = a, a
        Xm = 攝夕a, :, :]                         # 3(A-1) x M
        Y竢ｦm = 攝麓a, :] .- 攝ｦ(Xm)                 # M
        Xmn = (Xm[:, :, nax] .- Xm[:, nax, :])  # 3(A-1) x M x N

        x0 = 攝､.hyperparameters[a, :]
        # x0 = 攝.regression_fold(xout)
        # fout, xout = optimizer(x -> likelihood(x, Xmn, Y竢ｦm), x0, bounds[a, :, :],
        #                        m=10, factr=1e7, pgtol=1e-5,
        #                        iprint=-1, maxfun=15000, maxiter=15000)
        xout = x0

        攝､.hyperparameters[a, :] = xout
        # 攝､.hyperparameters[i, :] = 攝.hyperparameters_expand(xout)
        # append(sendbuf, hyperparameters)
    end

    # MPI.ScatterV(sakdfh)

    numbers = model.numbers
    model.kernel_hyperparameters = 攝.kernel_hyperparameters(攝､.hyperparameters, numbers)
    model.optimized = false
end

end
